# Data Manifest

This document enumerates datasets and external resources used by the project.

## Dataset Governance Protocol

When introducing a new dataset:

- Append an entry to `docs/data_manifest.md`.
- Provide or update schema documentation explaining structure and fields.
- Add privacy notes clarifying handling of sensitive data and consent.
- Audit against [Data Security and Compliance](data_security.md) and the
  [Dependency Registry](dependency_registry.md).

## Internal datasets

### `data/emotion_registry.json`
- **Description:** Lists additional emotion labels recognized by `emotional_state.py`.
- **Regeneration:** Edit the JSON file or allow `emotional_state` to recreate it if missing.
- **License:** MIT (repository license).

### `data/feedback.json`
- **Description:** Stores user or automated feedback events.
- **Regeneration:** Populated automatically by feedback logging routines.
- **License:** MIT.

### `data/quality_history.json`
- **Description:** Historical scores from lint, type and coverage checks generated by `scripts/quality_score.py`.
- **Regeneration:** Run `python scripts/quality_score.py`.
- **License:** MIT.

### `data/spiral_cortex_memory.jsonl`
- **Description:** Insight log appended by `memory/spiral_cortex.log_insight` during retrieval operations.
- **Regeneration:** Generated automatically when `log_insight` is invoked.
- **License:** MIT.

### `data/ontology_schema.sql`
- **Description:** SQL schema defining event‑to‑symbol mappings.
- **Regeneration:** Apply the SQL file to initialize a database.
- **License:** MIT.

## External resources

### GitHub source repositories
- **Location:** `data/github/`
- **Description:** Markdown and text files fetched from repositories listed in `learning_sources/github_repos.txt`.
- **Regeneration:** `python ml/data_pipeline.py --update` downloads the latest sources.
- **License:** Each repository retains its original license.

### Project Gutenberg books
- **Location:** `data/gutenberg/`
- **URL:** https://www.gutenberg.org/
- **Description:** Cleaned public‑domain texts used for training.
- **Regeneration:** Run `python ml/data_pipeline.py --update` or
  `python -m INANNA_AI.learning.project_gutenberg "Title"`.
- **License:** Public domain; see https://www.gutenberg.org/policy/license.html.

### Training corpus
- **Location:** `data/training_corpus/`
- **Description:** Aggregated corpus assembled by the data pipeline from GitHub and Project Gutenberg sources.
- **Regeneration:** `python ml/data_pipeline.py` (use `--embed` to add vector embeddings).
- **License:** Derived from upstream sources; follow their licenses.

### `data/aspects/`
- **Description:** Aspect analysis logs such as phonetic or semantic metrics produced by helpers in [`aspect_processor.py`](../aspect_processor.py).
- **Ingestion:** `analyze_*` functions append JSON lines to aspect‑specific log files.
- **Status:** in-progress.
- **Reference:** [`aspect_processor.py`](../aspect_processor.py).

### `data/benchmarks/`
- **Description:** JSON summaries from performance benchmarks.
- **Ingestion:** Generated by scripts in [`benchmarks/`](../benchmarks/), e.g. `memory_store_benchmark.py` and `llm_throughput_benchmark.py`.
- **Status:** in-progress.
- **Reference:** [`benchmarks/README.md`](../benchmarks/README.md).

### `data/physical/`
- **Description:** Serialized raw physical events (audio, video, or text) and metadata captured during runtime.
- **Ingestion:** Stored by [`store_physical_event`](../src/core/memory_physical.py) from `src/core/memory_physical.py`.
- **Status:** planned.
- **Reference:** [`src/core/memory_physical.py`](../src/core/memory_physical.py).

### `data/sacred/`
- **Description:** Latent vectors and generated glyph artifacts from sacred VAE experiments.
- **Ingestion:** Produced by [`generate_sacred_glyph`](../memory/sacred.py) in `memory/sacred.py`.
- **Status:** planned.
- **Reference:** [`memory/sacred.py`](../memory/sacred.py).
